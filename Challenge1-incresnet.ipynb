{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5715c16-28b8-44fa-b518-92a19e7e61d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "import splitfolders\n",
    "import visualkeras\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b03cc283-53b6-4be7-8284-c7dcee143554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fc7b2bc-f9c3-47c4-8d2f-cace73009bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/irfanmasudi/ANNDL/Challenge\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/irfanmasudi/ANNDL/Challenge/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f1bb39-acb9-42f5-965b-4f594765bf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset folders \n",
    "dataset_dir = 'datasets'\n",
    "training_dir = os.path.join(dataset_dir, 'train')\n",
    "validation_dir = os.path.join(dataset_dir, 'val')\n",
    "#test_dir = os.path.join(dataset_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d962f92-3963-459f-be9a-d9f0d6904886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot example images from dataset\n",
    "labels = ['Apple',       # 0\n",
    "          'Blueberry',   # 1\n",
    "          'Cherry',      # 2\n",
    "          'Corn',        # 3\n",
    "          'Grape',       # 4\n",
    "          'Orange',      # 5\n",
    "          'Peach',       # 6\n",
    "          'Pepper',      # 7\n",
    "          'Potato',      # 8\n",
    "          'Raspberry',   # 9\n",
    "          'Soybean',     # 10\n",
    "          'Squash',      # 11\n",
    "          'Strawberry',  # 12\n",
    "          'Tomato']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89b4e415-0166-4891-9e65-1b5fb514fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "incresnet = tf.keras.applications.InceptionResNetV2(\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36b6fd6c-8eac-4461-b1bc-f08c728c8bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67279 images belonging to 14 classes.\n",
      "Found 3552 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Creating an instance of ImageDataGenerator without Data Augmentation\n",
    "noaug_train_data_gen = ImageDataGenerator(preprocessing_function=tfk.applications.inception_resnet_v2.preprocess_input)\n",
    "valid_data_gen       = ImageDataGenerator(preprocessing_function=tfk.applications.inception_resnet_v2.preprocess_input)\n",
    "\n",
    "train_gen = noaug_train_data_gen.flow_from_directory(directory=training_dir,\n",
    "                                                           target_size=(299,299),\n",
    "                                                           color_mode='rgb',\n",
    "                                                           classes=None,\n",
    "                                                           class_mode='categorical',\n",
    "                                                           batch_size=64,\n",
    "                                                           shuffle=True,\n",
    "                                                           seed=seed)\n",
    "\n",
    "valid_gen = valid_data_gen.flow_from_directory(directory=validation_dir,\n",
    "                                               target_size=(299,299),\n",
    "                                               color_mode='rgb',\n",
    "                                               classes=None,\n",
    "                                               class_mode='categorical',\n",
    "                                               batch_size=64,\n",
    "                                               shuffle=False, # no need to shuffle validation set\n",
    "                                               seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e26676c0-6998-4d11-8d15-7b20308aee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_batch(generator):\n",
    "    batch = next(generator)\n",
    "\n",
    "    image = batch[0]\n",
    "    target = batch[1]\n",
    "\n",
    "    print(\"(Input) image shape:\", image.shape)\n",
    "    print(\"Target shape:\",target.shape)\n",
    "\n",
    "    # Visualize only the first sample\n",
    "    image = image[0]\n",
    "    target = target[0]\n",
    "    target_idx = np.argmax(target)\n",
    "    print()\n",
    "    print(\"Categorical label:\", target)\n",
    "    print(\"Label:\", target_idx)\n",
    "    print(\"Class name:\", labels[target_idx])\n",
    "    \n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    plt.imshow(np.uint8(image))\n",
    "    plt.show()\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dec5ad6b-16bf-4a81-8037-e85edbb77fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Input) image shape: (64, 299, 299, 3)\n",
      "Target shape: (64, 14)\n",
      "\n",
      "Categorical label: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "Label: 7\n",
      "Class name: Pepper\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a sample from dataset and show info\n",
    "_ = get_next_batch(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1cdc3f3f-eb38-4122-b433-f7e6830b4073",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tfk.metrics.TruePositives(name='tp'),\n",
    "      tfk.metrics.FalsePositives(name='fp'),\n",
    "      tfk.metrics.TrueNegatives(name='tn'),\n",
    "      tfk.metrics.FalseNegatives(name='fn'), \n",
    "      tfk.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tfk.metrics.Precision(name='precision'),\n",
    "      tfk.metrics.Recall(name='recall'),\n",
    "      tfk.metrics.AUC(name='auc'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48f5dcb2-1fbf-43a4-8774-75238502fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "incresnet.trainable = False\n",
    "\n",
    "inputs = tfk.Input(shape=(299,299,3))\n",
    "\n",
    "model = incresnet(inputs)\n",
    "\n",
    "# Rebuild top\n",
    "x = tfkl.GlobalAveragePooling2D(name=\"avg_pool\")(model)\n",
    "\n",
    "#x = tfkl.BatchNormalization()(x)\n",
    "\n",
    "x = tfkl.Dropout(0.3, seed=seed)(x)\n",
    "x = tfkl.Dense(\n",
    "    256, \n",
    "    activation='relu',\n",
    "    kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n",
    "\n",
    "#x = tfkl.BatchNormalization()(x)\n",
    "\n",
    "x = tfkl.Dropout(0.3, seed=seed)(x)\n",
    "x = tfkl.Dense(\n",
    "    256, \n",
    "    activation='relu',\n",
    "    kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n",
    "\n",
    "#x = tfkl.BatchNormalization()(x)\n",
    "\n",
    "x = tfkl.Dropout(0.3, seed=seed)(x)\n",
    "x = tfkl.Dense(\n",
    "    256, \n",
    "    activation='relu',\n",
    "    kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n",
    "\n",
    "#x = tfkl.BatchNormalization()(x)\n",
    "\n",
    "x = tfkl.Dropout(0.3, seed=seed)(x)\n",
    "x = tfkl.Dense(\n",
    "    256, \n",
    "    activation='relu',\n",
    "    kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n",
    "\n",
    "#x = tfkl.BatchNormalization()(x)\n",
    "\n",
    "x = tfkl.Dropout(0.3, seed=seed)(x)\n",
    "x = tfkl.Dense(\n",
    "    256, \n",
    "    activation='relu',\n",
    "    kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n",
    "\n",
    "#x = tfkl.BatchNormalization()(x)\n",
    "\n",
    "x = tfkl.Dropout(0.3, seed=seed)(x)\n",
    "outputs = tfkl.Dense(\n",
    "    14, \n",
    "    activation='softmax',\n",
    "    kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n",
    "\n",
    "tl_model = tfk.Model(inputs=inputs, outputs=outputs, name=\"IncResnet\")\n",
    "optimizer = tfk.optimizers.Adam()\n",
    "tl_model.compile(\n",
    "    optimizer=optimizer, loss=tfk.losses.CategoricalCrossentropy(), metrics=METRICS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db9a9c7d-0a2c-4094-8ffc-56d994c18a6d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2 False\n",
      "1 conv2d_203 False\n",
      "2 batch_normalization_203 False\n",
      "3 activation_203 False\n",
      "4 conv2d_204 False\n",
      "5 batch_normalization_204 False\n",
      "6 activation_204 False\n",
      "7 conv2d_205 False\n",
      "8 batch_normalization_205 False\n",
      "9 activation_205 False\n",
      "10 max_pooling2d_4 False\n",
      "11 conv2d_206 False\n",
      "12 batch_normalization_206 False\n",
      "13 activation_206 False\n",
      "14 conv2d_207 False\n",
      "15 batch_normalization_207 False\n",
      "16 activation_207 False\n",
      "17 max_pooling2d_5 False\n",
      "18 conv2d_211 False\n",
      "19 batch_normalization_211 False\n",
      "20 activation_211 False\n",
      "21 conv2d_209 False\n",
      "22 conv2d_212 False\n",
      "23 batch_normalization_209 False\n",
      "24 batch_normalization_212 False\n",
      "25 activation_209 False\n",
      "26 activation_212 False\n",
      "27 average_pooling2d_1 False\n",
      "28 conv2d_208 False\n",
      "29 conv2d_210 False\n",
      "30 conv2d_213 False\n",
      "31 conv2d_214 False\n",
      "32 batch_normalization_208 False\n",
      "33 batch_normalization_210 False\n",
      "34 batch_normalization_213 False\n",
      "35 batch_normalization_214 False\n",
      "36 activation_208 False\n",
      "37 activation_210 False\n",
      "38 activation_213 False\n",
      "39 activation_214 False\n",
      "40 mixed_5b False\n",
      "41 conv2d_218 False\n",
      "42 batch_normalization_218 False\n",
      "43 activation_218 False\n",
      "44 conv2d_216 False\n",
      "45 conv2d_219 False\n",
      "46 batch_normalization_216 False\n",
      "47 batch_normalization_219 False\n",
      "48 activation_216 False\n",
      "49 activation_219 False\n",
      "50 conv2d_215 False\n",
      "51 conv2d_217 False\n",
      "52 conv2d_220 False\n",
      "53 batch_normalization_215 False\n",
      "54 batch_normalization_217 False\n",
      "55 batch_normalization_220 False\n",
      "56 activation_215 False\n",
      "57 activation_217 False\n",
      "58 activation_220 False\n",
      "59 block35_1_mixed False\n",
      "60 block35_1_conv False\n",
      "61 block35_1 False\n",
      "62 block35_1_ac False\n",
      "63 conv2d_224 False\n",
      "64 batch_normalization_224 False\n",
      "65 activation_224 False\n",
      "66 conv2d_222 False\n",
      "67 conv2d_225 False\n",
      "68 batch_normalization_222 False\n",
      "69 batch_normalization_225 False\n",
      "70 activation_222 False\n",
      "71 activation_225 False\n",
      "72 conv2d_221 False\n",
      "73 conv2d_223 False\n",
      "74 conv2d_226 False\n",
      "75 batch_normalization_221 False\n",
      "76 batch_normalization_223 False\n",
      "77 batch_normalization_226 False\n",
      "78 activation_221 False\n",
      "79 activation_223 False\n",
      "80 activation_226 False\n",
      "81 block35_2_mixed False\n",
      "82 block35_2_conv False\n",
      "83 block35_2 False\n",
      "84 block35_2_ac False\n",
      "85 conv2d_230 False\n",
      "86 batch_normalization_230 False\n",
      "87 activation_230 False\n",
      "88 conv2d_228 False\n",
      "89 conv2d_231 False\n",
      "90 batch_normalization_228 False\n",
      "91 batch_normalization_231 False\n",
      "92 activation_228 False\n",
      "93 activation_231 False\n",
      "94 conv2d_227 False\n",
      "95 conv2d_229 False\n",
      "96 conv2d_232 False\n",
      "97 batch_normalization_227 False\n",
      "98 batch_normalization_229 False\n",
      "99 batch_normalization_232 False\n",
      "100 activation_227 False\n",
      "101 activation_229 False\n",
      "102 activation_232 False\n",
      "103 block35_3_mixed False\n",
      "104 block35_3_conv False\n",
      "105 block35_3 False\n",
      "106 block35_3_ac False\n",
      "107 conv2d_236 False\n",
      "108 batch_normalization_236 False\n",
      "109 activation_236 False\n",
      "110 conv2d_234 False\n",
      "111 conv2d_237 False\n",
      "112 batch_normalization_234 False\n",
      "113 batch_normalization_237 False\n",
      "114 activation_234 False\n",
      "115 activation_237 False\n",
      "116 conv2d_233 False\n",
      "117 conv2d_235 False\n",
      "118 conv2d_238 False\n",
      "119 batch_normalization_233 False\n",
      "120 batch_normalization_235 False\n",
      "121 batch_normalization_238 False\n",
      "122 activation_233 False\n",
      "123 activation_235 False\n",
      "124 activation_238 False\n",
      "125 block35_4_mixed False\n",
      "126 block35_4_conv False\n",
      "127 block35_4 False\n",
      "128 block35_4_ac False\n",
      "129 conv2d_242 False\n",
      "130 batch_normalization_242 False\n",
      "131 activation_242 False\n",
      "132 conv2d_240 False\n",
      "133 conv2d_243 False\n",
      "134 batch_normalization_240 False\n",
      "135 batch_normalization_243 False\n",
      "136 activation_240 False\n",
      "137 activation_243 False\n",
      "138 conv2d_239 False\n",
      "139 conv2d_241 False\n",
      "140 conv2d_244 False\n",
      "141 batch_normalization_239 False\n",
      "142 batch_normalization_241 False\n",
      "143 batch_normalization_244 False\n",
      "144 activation_239 False\n",
      "145 activation_241 False\n",
      "146 activation_244 False\n",
      "147 block35_5_mixed False\n",
      "148 block35_5_conv False\n",
      "149 block35_5 False\n",
      "150 block35_5_ac False\n",
      "151 conv2d_248 False\n",
      "152 batch_normalization_248 False\n",
      "153 activation_248 False\n",
      "154 conv2d_246 False\n",
      "155 conv2d_249 False\n",
      "156 batch_normalization_246 False\n",
      "157 batch_normalization_249 False\n",
      "158 activation_246 False\n",
      "159 activation_249 False\n",
      "160 conv2d_245 False\n",
      "161 conv2d_247 False\n",
      "162 conv2d_250 False\n",
      "163 batch_normalization_245 False\n",
      "164 batch_normalization_247 False\n",
      "165 batch_normalization_250 False\n",
      "166 activation_245 False\n",
      "167 activation_247 False\n",
      "168 activation_250 False\n",
      "169 block35_6_mixed False\n",
      "170 block35_6_conv False\n",
      "171 block35_6 False\n",
      "172 block35_6_ac False\n",
      "173 conv2d_254 False\n",
      "174 batch_normalization_254 False\n",
      "175 activation_254 False\n",
      "176 conv2d_252 False\n",
      "177 conv2d_255 False\n",
      "178 batch_normalization_252 False\n",
      "179 batch_normalization_255 False\n",
      "180 activation_252 False\n",
      "181 activation_255 False\n",
      "182 conv2d_251 False\n",
      "183 conv2d_253 False\n",
      "184 conv2d_256 False\n",
      "185 batch_normalization_251 False\n",
      "186 batch_normalization_253 False\n",
      "187 batch_normalization_256 False\n",
      "188 activation_251 False\n",
      "189 activation_253 False\n",
      "190 activation_256 False\n",
      "191 block35_7_mixed False\n",
      "192 block35_7_conv False\n",
      "193 block35_7 False\n",
      "194 block35_7_ac False\n",
      "195 conv2d_260 False\n",
      "196 batch_normalization_260 False\n",
      "197 activation_260 False\n",
      "198 conv2d_258 False\n",
      "199 conv2d_261 False\n",
      "200 batch_normalization_258 False\n",
      "201 batch_normalization_261 False\n",
      "202 activation_258 False\n",
      "203 activation_261 False\n",
      "204 conv2d_257 False\n",
      "205 conv2d_259 False\n",
      "206 conv2d_262 False\n",
      "207 batch_normalization_257 False\n",
      "208 batch_normalization_259 False\n",
      "209 batch_normalization_262 False\n",
      "210 activation_257 False\n",
      "211 activation_259 False\n",
      "212 activation_262 False\n",
      "213 block35_8_mixed False\n",
      "214 block35_8_conv False\n",
      "215 block35_8 False\n",
      "216 block35_8_ac False\n",
      "217 conv2d_266 False\n",
      "218 batch_normalization_266 False\n",
      "219 activation_266 False\n",
      "220 conv2d_264 False\n",
      "221 conv2d_267 False\n",
      "222 batch_normalization_264 False\n",
      "223 batch_normalization_267 False\n",
      "224 activation_264 False\n",
      "225 activation_267 False\n",
      "226 conv2d_263 False\n",
      "227 conv2d_265 False\n",
      "228 conv2d_268 False\n",
      "229 batch_normalization_263 False\n",
      "230 batch_normalization_265 False\n",
      "231 batch_normalization_268 False\n",
      "232 activation_263 False\n",
      "233 activation_265 False\n",
      "234 activation_268 False\n",
      "235 block35_9_mixed False\n",
      "236 block35_9_conv False\n",
      "237 block35_9 False\n",
      "238 block35_9_ac False\n",
      "239 conv2d_272 False\n",
      "240 batch_normalization_272 False\n",
      "241 activation_272 False\n",
      "242 conv2d_270 False\n",
      "243 conv2d_273 False\n",
      "244 batch_normalization_270 False\n",
      "245 batch_normalization_273 False\n",
      "246 activation_270 False\n",
      "247 activation_273 False\n",
      "248 conv2d_269 False\n",
      "249 conv2d_271 False\n",
      "250 conv2d_274 False\n",
      "251 batch_normalization_269 False\n",
      "252 batch_normalization_271 False\n",
      "253 batch_normalization_274 False\n",
      "254 activation_269 False\n",
      "255 activation_271 False\n",
      "256 activation_274 False\n",
      "257 block35_10_mixed False\n",
      "258 block35_10_conv False\n",
      "259 block35_10 False\n",
      "260 block35_10_ac False\n",
      "261 conv2d_276 False\n",
      "262 batch_normalization_276 False\n",
      "263 activation_276 False\n",
      "264 conv2d_277 False\n",
      "265 batch_normalization_277 False\n",
      "266 activation_277 False\n",
      "267 conv2d_275 False\n",
      "268 conv2d_278 False\n",
      "269 batch_normalization_275 False\n",
      "270 batch_normalization_278 False\n",
      "271 activation_275 False\n",
      "272 activation_278 False\n",
      "273 max_pooling2d_6 False\n",
      "274 mixed_6a False\n",
      "275 conv2d_280 False\n",
      "276 batch_normalization_280 False\n",
      "277 activation_280 False\n",
      "278 conv2d_281 False\n",
      "279 batch_normalization_281 False\n",
      "280 activation_281 False\n",
      "281 conv2d_279 False\n",
      "282 conv2d_282 False\n",
      "283 batch_normalization_279 False\n",
      "284 batch_normalization_282 False\n",
      "285 activation_279 False\n",
      "286 activation_282 False\n",
      "287 block17_1_mixed False\n",
      "288 block17_1_conv False\n",
      "289 block17_1 False\n",
      "290 block17_1_ac False\n",
      "291 conv2d_284 False\n",
      "292 batch_normalization_284 False\n",
      "293 activation_284 False\n",
      "294 conv2d_285 False\n",
      "295 batch_normalization_285 False\n",
      "296 activation_285 False\n",
      "297 conv2d_283 False\n",
      "298 conv2d_286 False\n",
      "299 batch_normalization_283 False\n",
      "300 batch_normalization_286 False\n",
      "301 activation_283 False\n",
      "302 activation_286 False\n",
      "303 block17_2_mixed False\n",
      "304 block17_2_conv False\n",
      "305 block17_2 False\n",
      "306 block17_2_ac False\n",
      "307 conv2d_288 False\n",
      "308 batch_normalization_288 False\n",
      "309 activation_288 False\n",
      "310 conv2d_289 False\n",
      "311 batch_normalization_289 False\n",
      "312 activation_289 False\n",
      "313 conv2d_287 False\n",
      "314 conv2d_290 False\n",
      "315 batch_normalization_287 False\n",
      "316 batch_normalization_290 False\n",
      "317 activation_287 False\n",
      "318 activation_290 False\n",
      "319 block17_3_mixed False\n",
      "320 block17_3_conv False\n",
      "321 block17_3 False\n",
      "322 block17_3_ac False\n",
      "323 conv2d_292 False\n",
      "324 batch_normalization_292 False\n",
      "325 activation_292 False\n",
      "326 conv2d_293 False\n",
      "327 batch_normalization_293 False\n",
      "328 activation_293 False\n",
      "329 conv2d_291 False\n",
      "330 conv2d_294 False\n",
      "331 batch_normalization_291 False\n",
      "332 batch_normalization_294 False\n",
      "333 activation_291 False\n",
      "334 activation_294 False\n",
      "335 block17_4_mixed False\n",
      "336 block17_4_conv False\n",
      "337 block17_4 False\n",
      "338 block17_4_ac False\n",
      "339 conv2d_296 False\n",
      "340 batch_normalization_296 False\n",
      "341 activation_296 False\n",
      "342 conv2d_297 False\n",
      "343 batch_normalization_297 False\n",
      "344 activation_297 False\n",
      "345 conv2d_295 False\n",
      "346 conv2d_298 False\n",
      "347 batch_normalization_295 False\n",
      "348 batch_normalization_298 False\n",
      "349 activation_295 False\n",
      "350 activation_298 False\n",
      "351 block17_5_mixed False\n",
      "352 block17_5_conv False\n",
      "353 block17_5 False\n",
      "354 block17_5_ac False\n",
      "355 conv2d_300 False\n",
      "356 batch_normalization_300 False\n",
      "357 activation_300 False\n",
      "358 conv2d_301 False\n",
      "359 batch_normalization_301 False\n",
      "360 activation_301 False\n",
      "361 conv2d_299 False\n",
      "362 conv2d_302 False\n",
      "363 batch_normalization_299 False\n",
      "364 batch_normalization_302 False\n",
      "365 activation_299 False\n",
      "366 activation_302 False\n",
      "367 block17_6_mixed False\n",
      "368 block17_6_conv False\n",
      "369 block17_6 False\n",
      "370 block17_6_ac False\n",
      "371 conv2d_304 False\n",
      "372 batch_normalization_304 False\n",
      "373 activation_304 False\n",
      "374 conv2d_305 False\n",
      "375 batch_normalization_305 False\n",
      "376 activation_305 False\n",
      "377 conv2d_303 False\n",
      "378 conv2d_306 False\n",
      "379 batch_normalization_303 False\n",
      "380 batch_normalization_306 False\n",
      "381 activation_303 False\n",
      "382 activation_306 False\n",
      "383 block17_7_mixed False\n",
      "384 block17_7_conv False\n",
      "385 block17_7 False\n",
      "386 block17_7_ac False\n",
      "387 conv2d_308 False\n",
      "388 batch_normalization_308 False\n",
      "389 activation_308 False\n",
      "390 conv2d_309 False\n",
      "391 batch_normalization_309 False\n",
      "392 activation_309 False\n",
      "393 conv2d_307 False\n",
      "394 conv2d_310 False\n",
      "395 batch_normalization_307 False\n",
      "396 batch_normalization_310 False\n",
      "397 activation_307 False\n",
      "398 activation_310 False\n",
      "399 block17_8_mixed False\n",
      "400 block17_8_conv False\n",
      "401 block17_8 False\n",
      "402 block17_8_ac False\n",
      "403 conv2d_312 False\n",
      "404 batch_normalization_312 False\n",
      "405 activation_312 False\n",
      "406 conv2d_313 False\n",
      "407 batch_normalization_313 False\n",
      "408 activation_313 False\n",
      "409 conv2d_311 False\n",
      "410 conv2d_314 False\n",
      "411 batch_normalization_311 False\n",
      "412 batch_normalization_314 False\n",
      "413 activation_311 False\n",
      "414 activation_314 False\n",
      "415 block17_9_mixed False\n",
      "416 block17_9_conv False\n",
      "417 block17_9 False\n",
      "418 block17_9_ac False\n",
      "419 conv2d_316 False\n",
      "420 batch_normalization_316 False\n",
      "421 activation_316 False\n",
      "422 conv2d_317 False\n",
      "423 batch_normalization_317 False\n",
      "424 activation_317 False\n",
      "425 conv2d_315 False\n",
      "426 conv2d_318 False\n",
      "427 batch_normalization_315 False\n",
      "428 batch_normalization_318 False\n",
      "429 activation_315 False\n",
      "430 activation_318 False\n",
      "431 block17_10_mixed False\n",
      "432 block17_10_conv False\n",
      "433 block17_10 False\n",
      "434 block17_10_ac False\n",
      "435 conv2d_320 False\n",
      "436 batch_normalization_320 False\n",
      "437 activation_320 False\n",
      "438 conv2d_321 False\n",
      "439 batch_normalization_321 False\n",
      "440 activation_321 False\n",
      "441 conv2d_319 False\n",
      "442 conv2d_322 False\n",
      "443 batch_normalization_319 False\n",
      "444 batch_normalization_322 False\n",
      "445 activation_319 False\n",
      "446 activation_322 False\n",
      "447 block17_11_mixed False\n",
      "448 block17_11_conv False\n",
      "449 block17_11 False\n",
      "450 block17_11_ac False\n",
      "451 conv2d_324 False\n",
      "452 batch_normalization_324 False\n",
      "453 activation_324 False\n",
      "454 conv2d_325 False\n",
      "455 batch_normalization_325 False\n",
      "456 activation_325 False\n",
      "457 conv2d_323 False\n",
      "458 conv2d_326 False\n",
      "459 batch_normalization_323 False\n",
      "460 batch_normalization_326 False\n",
      "461 activation_323 False\n",
      "462 activation_326 False\n",
      "463 block17_12_mixed False\n",
      "464 block17_12_conv False\n",
      "465 block17_12 False\n",
      "466 block17_12_ac False\n",
      "467 conv2d_328 False\n",
      "468 batch_normalization_328 False\n",
      "469 activation_328 False\n",
      "470 conv2d_329 False\n",
      "471 batch_normalization_329 False\n",
      "472 activation_329 False\n",
      "473 conv2d_327 False\n",
      "474 conv2d_330 False\n",
      "475 batch_normalization_327 False\n",
      "476 batch_normalization_330 False\n",
      "477 activation_327 False\n",
      "478 activation_330 False\n",
      "479 block17_13_mixed False\n",
      "480 block17_13_conv False\n",
      "481 block17_13 False\n",
      "482 block17_13_ac False\n",
      "483 conv2d_332 False\n",
      "484 batch_normalization_332 False\n",
      "485 activation_332 False\n",
      "486 conv2d_333 False\n",
      "487 batch_normalization_333 False\n",
      "488 activation_333 False\n",
      "489 conv2d_331 False\n",
      "490 conv2d_334 False\n",
      "491 batch_normalization_331 False\n",
      "492 batch_normalization_334 False\n",
      "493 activation_331 False\n",
      "494 activation_334 False\n",
      "495 block17_14_mixed False\n",
      "496 block17_14_conv False\n",
      "497 block17_14 False\n",
      "498 block17_14_ac False\n",
      "499 conv2d_336 False\n",
      "500 batch_normalization_336 False\n",
      "501 activation_336 False\n",
      "502 conv2d_337 False\n",
      "503 batch_normalization_337 False\n",
      "504 activation_337 False\n",
      "505 conv2d_335 False\n",
      "506 conv2d_338 False\n",
      "507 batch_normalization_335 False\n",
      "508 batch_normalization_338 False\n",
      "509 activation_335 False\n",
      "510 activation_338 False\n",
      "511 block17_15_mixed False\n",
      "512 block17_15_conv False\n",
      "513 block17_15 False\n",
      "514 block17_15_ac False\n",
      "515 conv2d_340 False\n",
      "516 batch_normalization_340 False\n",
      "517 activation_340 False\n",
      "518 conv2d_341 False\n",
      "519 batch_normalization_341 False\n",
      "520 activation_341 False\n",
      "521 conv2d_339 False\n",
      "522 conv2d_342 False\n",
      "523 batch_normalization_339 False\n",
      "524 batch_normalization_342 False\n",
      "525 activation_339 False\n",
      "526 activation_342 False\n",
      "527 block17_16_mixed False\n",
      "528 block17_16_conv False\n",
      "529 block17_16 False\n",
      "530 block17_16_ac False\n",
      "531 conv2d_344 False\n",
      "532 batch_normalization_344 False\n",
      "533 activation_344 False\n",
      "534 conv2d_345 False\n",
      "535 batch_normalization_345 False\n",
      "536 activation_345 False\n",
      "537 conv2d_343 False\n",
      "538 conv2d_346 False\n",
      "539 batch_normalization_343 False\n",
      "540 batch_normalization_346 False\n",
      "541 activation_343 False\n",
      "542 activation_346 False\n",
      "543 block17_17_mixed False\n",
      "544 block17_17_conv False\n",
      "545 block17_17 False\n",
      "546 block17_17_ac False\n",
      "547 conv2d_348 False\n",
      "548 batch_normalization_348 False\n",
      "549 activation_348 False\n",
      "550 conv2d_349 False\n",
      "551 batch_normalization_349 False\n",
      "552 activation_349 False\n",
      "553 conv2d_347 False\n",
      "554 conv2d_350 False\n",
      "555 batch_normalization_347 False\n",
      "556 batch_normalization_350 False\n",
      "557 activation_347 False\n",
      "558 activation_350 False\n",
      "559 block17_18_mixed False\n",
      "560 block17_18_conv False\n",
      "561 block17_18 False\n",
      "562 block17_18_ac False\n",
      "563 conv2d_352 False\n",
      "564 batch_normalization_352 False\n",
      "565 activation_352 False\n",
      "566 conv2d_353 False\n",
      "567 batch_normalization_353 False\n",
      "568 activation_353 False\n",
      "569 conv2d_351 False\n",
      "570 conv2d_354 False\n",
      "571 batch_normalization_351 False\n",
      "572 batch_normalization_354 False\n",
      "573 activation_351 False\n",
      "574 activation_354 False\n",
      "575 block17_19_mixed False\n",
      "576 block17_19_conv False\n",
      "577 block17_19 False\n",
      "578 block17_19_ac False\n",
      "579 conv2d_356 False\n",
      "580 batch_normalization_356 False\n",
      "581 activation_356 False\n",
      "582 conv2d_357 False\n",
      "583 batch_normalization_357 False\n",
      "584 activation_357 False\n",
      "585 conv2d_355 False\n",
      "586 conv2d_358 False\n",
      "587 batch_normalization_355 False\n",
      "588 batch_normalization_358 False\n",
      "589 activation_355 False\n",
      "590 activation_358 False\n",
      "591 block17_20_mixed False\n",
      "592 block17_20_conv False\n",
      "593 block17_20 False\n",
      "594 block17_20_ac False\n",
      "595 conv2d_363 False\n",
      "596 batch_normalization_363 False\n",
      "597 activation_363 False\n",
      "598 conv2d_359 False\n",
      "599 conv2d_361 False\n",
      "600 conv2d_364 False\n",
      "601 batch_normalization_359 False\n",
      "602 batch_normalization_361 False\n",
      "603 batch_normalization_364 False\n",
      "604 activation_359 False\n",
      "605 activation_361 False\n",
      "606 activation_364 False\n",
      "607 conv2d_360 False\n",
      "608 conv2d_362 False\n",
      "609 conv2d_365 False\n",
      "610 batch_normalization_360 False\n",
      "611 batch_normalization_362 False\n",
      "612 batch_normalization_365 False\n",
      "613 activation_360 False\n",
      "614 activation_362 False\n",
      "615 activation_365 False\n",
      "616 max_pooling2d_7 False\n",
      "617 mixed_7a False\n",
      "618 conv2d_367 False\n",
      "619 batch_normalization_367 False\n",
      "620 activation_367 False\n",
      "621 conv2d_368 False\n",
      "622 batch_normalization_368 False\n",
      "623 activation_368 False\n",
      "624 conv2d_366 False\n",
      "625 conv2d_369 False\n",
      "626 batch_normalization_366 False\n",
      "627 batch_normalization_369 False\n",
      "628 activation_366 False\n",
      "629 activation_369 False\n",
      "630 block8_1_mixed False\n",
      "631 block8_1_conv False\n",
      "632 block8_1 False\n",
      "633 block8_1_ac False\n",
      "634 conv2d_371 False\n",
      "635 batch_normalization_371 False\n",
      "636 activation_371 False\n",
      "637 conv2d_372 False\n",
      "638 batch_normalization_372 False\n",
      "639 activation_372 False\n",
      "640 conv2d_370 False\n",
      "641 conv2d_373 False\n",
      "642 batch_normalization_370 False\n",
      "643 batch_normalization_373 False\n",
      "644 activation_370 False\n",
      "645 activation_373 False\n",
      "646 block8_2_mixed False\n",
      "647 block8_2_conv False\n",
      "648 block8_2 False\n",
      "649 block8_2_ac False\n",
      "650 conv2d_375 False\n",
      "651 batch_normalization_375 False\n",
      "652 activation_375 False\n",
      "653 conv2d_376 False\n",
      "654 batch_normalization_376 False\n",
      "655 activation_376 False\n",
      "656 conv2d_374 False\n",
      "657 conv2d_377 False\n",
      "658 batch_normalization_374 False\n",
      "659 batch_normalization_377 False\n",
      "660 activation_374 False\n",
      "661 activation_377 False\n",
      "662 block8_3_mixed False\n",
      "663 block8_3_conv False\n",
      "664 block8_3 False\n",
      "665 block8_3_ac False\n",
      "666 conv2d_379 False\n",
      "667 batch_normalization_379 False\n",
      "668 activation_379 False\n",
      "669 conv2d_380 False\n",
      "670 batch_normalization_380 False\n",
      "671 activation_380 False\n",
      "672 conv2d_378 False\n",
      "673 conv2d_381 False\n",
      "674 batch_normalization_378 False\n",
      "675 batch_normalization_381 False\n",
      "676 activation_378 False\n",
      "677 activation_381 False\n",
      "678 block8_4_mixed False\n",
      "679 block8_4_conv False\n",
      "680 block8_4 False\n",
      "681 block8_4_ac False\n",
      "682 conv2d_383 False\n",
      "683 batch_normalization_383 False\n",
      "684 activation_383 False\n",
      "685 conv2d_384 False\n",
      "686 batch_normalization_384 False\n",
      "687 activation_384 False\n",
      "688 conv2d_382 False\n",
      "689 conv2d_385 False\n",
      "690 batch_normalization_382 False\n",
      "691 batch_normalization_385 False\n",
      "692 activation_382 False\n",
      "693 activation_385 False\n",
      "694 block8_5_mixed False\n",
      "695 block8_5_conv False\n",
      "696 block8_5 False\n",
      "697 block8_5_ac False\n",
      "698 conv2d_387 False\n",
      "699 batch_normalization_387 False\n",
      "700 activation_387 False\n",
      "701 conv2d_388 False\n",
      "702 batch_normalization_388 False\n",
      "703 activation_388 False\n",
      "704 conv2d_386 False\n",
      "705 conv2d_389 False\n",
      "706 batch_normalization_386 False\n",
      "707 batch_normalization_389 False\n",
      "708 activation_386 False\n",
      "709 activation_389 False\n",
      "710 block8_6_mixed False\n",
      "711 block8_6_conv False\n",
      "712 block8_6 False\n",
      "713 block8_6_ac False\n",
      "714 conv2d_391 False\n",
      "715 batch_normalization_391 False\n",
      "716 activation_391 False\n",
      "717 conv2d_392 False\n",
      "718 batch_normalization_392 False\n",
      "719 activation_392 False\n",
      "720 conv2d_390 False\n",
      "721 conv2d_393 False\n",
      "722 batch_normalization_390 False\n",
      "723 batch_normalization_393 False\n",
      "724 activation_390 False\n",
      "725 activation_393 False\n",
      "726 block8_7_mixed False\n",
      "727 block8_7_conv False\n",
      "728 block8_7 False\n",
      "729 block8_7_ac False\n",
      "730 conv2d_395 False\n",
      "731 batch_normalization_395 False\n",
      "732 activation_395 False\n",
      "733 conv2d_396 False\n",
      "734 batch_normalization_396 False\n",
      "735 activation_396 False\n",
      "736 conv2d_394 False\n",
      "737 conv2d_397 False\n",
      "738 batch_normalization_394 False\n",
      "739 batch_normalization_397 False\n",
      "740 activation_394 False\n",
      "741 activation_397 False\n",
      "742 block8_8_mixed False\n",
      "743 block8_8_conv False\n",
      "744 block8_8 False\n",
      "745 block8_8_ac False\n",
      "746 conv2d_399 False\n",
      "747 batch_normalization_399 False\n",
      "748 activation_399 False\n",
      "749 conv2d_400 False\n",
      "750 batch_normalization_400 False\n",
      "751 activation_400 False\n",
      "752 conv2d_398 False\n",
      "753 conv2d_401 False\n",
      "754 batch_normalization_398 False\n",
      "755 batch_normalization_401 False\n",
      "756 activation_398 False\n",
      "757 activation_401 False\n",
      "758 block8_9_mixed False\n",
      "759 block8_9_conv False\n",
      "760 block8_9 False\n",
      "761 block8_9_ac False\n",
      "762 conv2d_403 False\n",
      "763 batch_normalization_403 False\n",
      "764 activation_403 False\n",
      "765 conv2d_404 False\n",
      "766 batch_normalization_404 True\n",
      "767 activation_404 True\n",
      "768 conv2d_402 True\n",
      "769 conv2d_405 True\n",
      "770 batch_normalization_402 True\n",
      "771 batch_normalization_405 True\n",
      "772 activation_402 True\n",
      "773 activation_405 True\n",
      "774 block8_10_mixed True\n",
      "775 block8_10_conv True\n",
      "776 block8_10 True\n",
      "777 conv_7b True\n",
      "778 conv_7b_bn True\n",
      "779 conv_7b_ac True\n",
      "Model: \"IncResnet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v2 (Functio (None, None, None, 1536)  54336736  \n",
      "_________________________________________________________________\n",
      "avg_pool (GlobalAveragePooli (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               393472    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 14)                3598      \n",
      "=================================================================\n",
      "Total params: 54,996,974\n",
      "Trainable params: 660,238\n",
      "Non-trainable params: 54,336,736\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Freeze first N layers, e.g., until 14th\n",
    "for i, layer in enumerate(tl_model.get_layer('inception_resnet_v2').layers[-14:]):\n",
    "    #if not isinstance(layer, tfkl.BatchNormalization):\n",
    "    layer.trainable = True\n",
    "for i, layer in enumerate(tl_model.get_layer('inception_resnet_v2').layers):\n",
    "    print(i, layer.name, layer.trainable)\n",
    "tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "975c96d7-5ca9-405e-9b0e-2e0f39293220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create folders and callbacks for training\n",
    "from datetime import datetime\n",
    "\n",
    "def create_folders_and_callbacks(model_name):\n",
    "    exps_dir = os.path.join('logs/incresnet')\n",
    "    if not os.path.exists(exps_dir):\n",
    "        os.makedirs(exps_dir)\n",
    "\n",
    "    now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "    exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "    if not os.path.exists(exp_dir):\n",
    "        os.makedirs(exp_dir)\n",
    "      \n",
    "    callbacks = []\n",
    "\n",
    "  # Model checkpoint\n",
    "  # ----------------\n",
    "    ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "\n",
    "    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n",
    "                                                     save_weights_only=False, # True to save only weights\n",
    "                                                     save_best_only=False) # True to save only the best epoch \n",
    "    callbacks.append(ckpt_callback)\n",
    "\n",
    "  # Visualize Learning on Tensorboard\n",
    "  # ---------------------------------\n",
    "    tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "    if not os.path.exists(tb_dir):\n",
    "        os.makedirs(tb_dir)\n",
    "      \n",
    "  # By default shows losses and metrics for both training and validation\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, \n",
    "                                               profile_batch=0,\n",
    "                                               histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n",
    "    callbacks.append(tb_callback)\n",
    "\n",
    "  # Early Stopping\n",
    "  # --------------\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_auc',\n",
    "                                                   patience=5, \n",
    "                                                   mode = \"max\",\n",
    "                                                   verbose=0,\n",
    "                                                   restore_best_weights=True)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8690a603-20c4-451f-a750-19b0a48e42a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1052/1052 [==============================] - 2324s 2s/step - loss: 0.8944 - tp: 40944.0000 - fp: 6919.0000 - tn: 867708.0000 - fn: 26335.0000 - accuracy: 0.9647 - precision: 0.8554 - recall: 0.6086 - auc: 0.9655 - val_loss: 0.2433 - val_tp: 3229.0000 - val_fp: 173.0000 - val_tn: 46003.0000 - val_fn: 323.0000 - val_accuracy: 0.9900 - val_precision: 0.9491 - val_recall: 0.9091 - val_auc: 0.9962\n",
      "Epoch 2/200\n",
      "1052/1052 [==============================] - 2328s 2s/step - loss: 0.4368 - tp: 56129.0000 - fp: 5469.0000 - tn: 869158.0000 - fn: 11150.0000 - accuracy: 0.9824 - precision: 0.9112 - recall: 0.8343 - auc: 0.9885 - val_loss: 0.2256 - val_tp: 3276.0000 - val_fp: 214.0000 - val_tn: 45962.0000 - val_fn: 276.0000 - val_accuracy: 0.9901 - val_precision: 0.9387 - val_recall: 0.9223 - val_auc: 0.9956\n",
      "Epoch 3/200\n",
      "1052/1052 [==============================] - 2267s 2s/step - loss: 0.3509 - tp: 58542.0000 - fp: 4658.0000 - tn: 869969.0000 - fn: 8737.0000 - accuracy: 0.9858 - precision: 0.9263 - recall: 0.8701 - auc: 0.9918 - val_loss: 0.1189 - val_tp: 3404.0000 - val_fp: 85.0000 - val_tn: 46091.0000 - val_fn: 148.0000 - val_accuracy: 0.9953 - val_precision: 0.9756 - val_recall: 0.9583 - val_auc: 0.9987\n",
      "Epoch 4/200\n",
      "1052/1052 [==============================] - 2284s 2s/step - loss: 0.3137 - tp: 59747.0000 - fp: 4221.0000 - tn: 870406.0000 - fn: 7532.0000 - accuracy: 0.9875 - precision: 0.9340 - recall: 0.8880 - auc: 0.9927 - val_loss: 0.1429 - val_tp: 3368.0000 - val_fp: 92.0000 - val_tn: 46084.0000 - val_fn: 184.0000 - val_accuracy: 0.9944 - val_precision: 0.9734 - val_recall: 0.9482 - val_auc: 0.9986\n",
      "Epoch 5/200\n",
      "1052/1052 [==============================] - 2284s 2s/step - loss: 0.2982 - tp: 60062.0000 - fp: 4071.0000 - tn: 870556.0000 - fn: 7217.0000 - accuracy: 0.9880 - precision: 0.9365 - recall: 0.8927 - auc: 0.9932 - val_loss: 0.1295 - val_tp: 3374.0000 - val_fp: 111.0000 - val_tn: 46065.0000 - val_fn: 178.0000 - val_accuracy: 0.9942 - val_precision: 0.9681 - val_recall: 0.9499 - val_auc: 0.9984\n",
      "Epoch 6/200\n",
      "1052/1052 [==============================] - 2291s 2s/step - loss: 0.2802 - tp: 60656.0000 - fp: 3802.0000 - tn: 870825.0000 - fn: 6623.0000 - accuracy: 0.9889 - precision: 0.9410 - recall: 0.9016 - auc: 0.9938 - val_loss: 0.1302 - val_tp: 3377.0000 - val_fp: 121.0000 - val_tn: 46055.0000 - val_fn: 175.0000 - val_accuracy: 0.9940 - val_precision: 0.9654 - val_recall: 0.9507 - val_auc: 0.9988\n",
      "Epoch 7/200\n",
      "1052/1052 [==============================] - 2297s 2s/step - loss: 0.2646 - tp: 61009.0000 - fp: 3660.0000 - tn: 870967.0000 - fn: 6270.0000 - accuracy: 0.9895 - precision: 0.9434 - recall: 0.9068 - auc: 0.9941 - val_loss: 0.1006 - val_tp: 3429.0000 - val_fp: 89.0000 - val_tn: 46087.0000 - val_fn: 123.0000 - val_accuracy: 0.9957 - val_precision: 0.9747 - val_recall: 0.9654 - val_auc: 0.9986\n",
      "Epoch 8/200\n",
      "1052/1052 [==============================] - 2283s 2s/step - loss: 0.2538 - tp: 61367.0000 - fp: 3535.0000 - tn: 871092.0000 - fn: 5912.0000 - accuracy: 0.9900 - precision: 0.9455 - recall: 0.9121 - auc: 0.9945 - val_loss: 0.0975 - val_tp: 3437.0000 - val_fp: 78.0000 - val_tn: 46098.0000 - val_fn: 115.0000 - val_accuracy: 0.9961 - val_precision: 0.9778 - val_recall: 0.9676 - val_auc: 0.9988\n",
      "Epoch 9/200\n",
      "1052/1052 [==============================] - 2291s 2s/step - loss: 0.2500 - tp: 61398.0000 - fp: 3458.0000 - tn: 871169.0000 - fn: 5881.0000 - accuracy: 0.9901 - precision: 0.9467 - recall: 0.9126 - auc: 0.9945 - val_loss: 0.1598 - val_tp: 3349.0000 - val_fp: 123.0000 - val_tn: 46053.0000 - val_fn: 203.0000 - val_accuracy: 0.9934 - val_precision: 0.9646 - val_recall: 0.9428 - val_auc: 0.9980\n",
      "Epoch 10/200\n",
      "1052/1052 [==============================] - 2321s 2s/step - loss: 0.2344 - tp: 61756.0000 - fp: 3323.0000 - tn: 871304.0000 - fn: 5523.0000 - accuracy: 0.9906 - precision: 0.9489 - recall: 0.9179 - auc: 0.9952 - val_loss: 0.1083 - val_tp: 3412.0000 - val_fp: 85.0000 - val_tn: 46091.0000 - val_fn: 140.0000 - val_accuracy: 0.9955 - val_precision: 0.9757 - val_recall: 0.9606 - val_auc: 0.9991\n",
      "Epoch 11/200\n",
      "1052/1052 [==============================] - 2295s 2s/step - loss: 0.2322 - tp: 61985.0000 - fp: 3232.0000 - tn: 871395.0000 - fn: 5294.0000 - accuracy: 0.9909 - precision: 0.9504 - recall: 0.9213 - auc: 0.9950 - val_loss: 0.1230 - val_tp: 3396.0000 - val_fp: 94.0000 - val_tn: 46082.0000 - val_fn: 156.0000 - val_accuracy: 0.9950 - val_precision: 0.9731 - val_recall: 0.9561 - val_auc: 0.9987\n",
      "Epoch 12/200\n",
      "1052/1052 [==============================] - 2295s 2s/step - loss: 0.2258 - tp: 62031.0000 - fp: 3209.0000 - tn: 871418.0000 - fn: 5248.0000 - accuracy: 0.9910 - precision: 0.9508 - recall: 0.9220 - auc: 0.9952 - val_loss: 0.1028 - val_tp: 3426.0000 - val_fp: 86.0000 - val_tn: 46090.0000 - val_fn: 126.0000 - val_accuracy: 0.9957 - val_precision: 0.9755 - val_recall: 0.9645 - val_auc: 0.9986\n",
      "Epoch 13/200\n",
      "1052/1052 [==============================] - 2299s 2s/step - loss: 0.2288 - tp: 62062.0000 - fp: 3220.0000 - tn: 871407.0000 - fn: 5217.0000 - accuracy: 0.9910 - precision: 0.9507 - recall: 0.9225 - auc: 0.9951 - val_loss: 0.1045 - val_tp: 3410.0000 - val_fp: 95.0000 - val_tn: 46081.0000 - val_fn: 142.0000 - val_accuracy: 0.9952 - val_precision: 0.9729 - val_recall: 0.9600 - val_auc: 0.9986\n",
      "Epoch 14/200\n",
      "1052/1052 [==============================] - 2295s 2s/step - loss: 0.2179 - tp: 62297.0000 - fp: 3106.0000 - tn: 871521.0000 - fn: 4982.0000 - accuracy: 0.9914 - precision: 0.9525 - recall: 0.9260 - auc: 0.9955 - val_loss: 0.0888 - val_tp: 3437.0000 - val_fp: 76.0000 - val_tn: 46100.0000 - val_fn: 115.0000 - val_accuracy: 0.9962 - val_precision: 0.9784 - val_recall: 0.9676 - val_auc: 0.9991\n",
      "Epoch 15/200\n",
      "1052/1052 [==============================] - 2304s 2s/step - loss: 0.2164 - tp: 62389.0000 - fp: 3103.0000 - tn: 871524.0000 - fn: 4890.0000 - accuracy: 0.9915 - precision: 0.9526 - recall: 0.9273 - auc: 0.9954 - val_loss: 0.0752 - val_tp: 3458.0000 - val_fp: 68.0000 - val_tn: 46108.0000 - val_fn: 94.0000 - val_accuracy: 0.9967 - val_precision: 0.9807 - val_recall: 0.9735 - val_auc: 0.9990\n",
      "Epoch 16/200\n",
      "1052/1052 [==============================] - 2301s 2s/step - loss: 0.2144 - tp: 62432.0000 - fp: 2989.0000 - tn: 871638.0000 - fn: 4847.0000 - accuracy: 0.9917 - precision: 0.9543 - recall: 0.9280 - auc: 0.9955 - val_loss: 0.0703 - val_tp: 3474.0000 - val_fp: 58.0000 - val_tn: 46118.0000 - val_fn: 78.0000 - val_accuracy: 0.9973 - val_precision: 0.9836 - val_recall: 0.9780 - val_auc: 0.9994\n",
      "Epoch 17/200\n",
      "1052/1052 [==============================] - 2297s 2s/step - loss: 0.2119 - tp: 62416.0000 - fp: 3065.0000 - tn: 871562.0000 - fn: 4863.0000 - accuracy: 0.9916 - precision: 0.9532 - recall: 0.9277 - auc: 0.9956 - val_loss: 0.0959 - val_tp: 3432.0000 - val_fp: 81.0000 - val_tn: 46095.0000 - val_fn: 120.0000 - val_accuracy: 0.9960 - val_precision: 0.9769 - val_recall: 0.9662 - val_auc: 0.9991\n",
      "Epoch 18/200\n",
      "1052/1052 [==============================] - 2306s 2s/step - loss: 0.2100 - tp: 62488.0000 - fp: 2958.0000 - tn: 871669.0000 - fn: 4791.0000 - accuracy: 0.9918 - precision: 0.9548 - recall: 0.9288 - auc: 0.9955 - val_loss: 0.0887 - val_tp: 3447.0000 - val_fp: 78.0000 - val_tn: 46098.0000 - val_fn: 105.0000 - val_accuracy: 0.9963 - val_precision: 0.9779 - val_recall: 0.9704 - val_auc: 0.9991\n",
      "Epoch 19/200\n",
      "1052/1052 [==============================] - 2305s 2s/step - loss: 0.2028 - tp: 62688.0000 - fp: 2879.0000 - tn: 871748.0000 - fn: 4591.0000 - accuracy: 0.9921 - precision: 0.9561 - recall: 0.9318 - auc: 0.9958 - val_loss: 0.0715 - val_tp: 3467.0000 - val_fp: 58.0000 - val_tn: 46118.0000 - val_fn: 85.0000 - val_accuracy: 0.9971 - val_precision: 0.9835 - val_recall: 0.9761 - val_auc: 0.9994\n",
      "Epoch 20/200\n",
      "1052/1052 [==============================] - 2302s 2s/step - loss: 0.2097 - tp: 62537.0000 - fp: 2948.0000 - tn: 871679.0000 - fn: 4742.0000 - accuracy: 0.9918 - precision: 0.9550 - recall: 0.9295 - auc: 0.9955 - val_loss: 0.0731 - val_tp: 3461.0000 - val_fp: 66.0000 - val_tn: 46110.0000 - val_fn: 91.0000 - val_accuracy: 0.9968 - val_precision: 0.9813 - val_recall: 0.9744 - val_auc: 0.9995\n",
      "Epoch 21/200\n",
      "1052/1052 [==============================] - 2285s 2s/step - loss: 0.2062 - tp: 62656.0000 - fp: 2907.0000 - tn: 871720.0000 - fn: 4623.0000 - accuracy: 0.9920 - precision: 0.9557 - recall: 0.9313 - auc: 0.9957 - val_loss: 0.0883 - val_tp: 3449.0000 - val_fp: 72.0000 - val_tn: 46104.0000 - val_fn: 103.0000 - val_accuracy: 0.9965 - val_precision: 0.9796 - val_recall: 0.9710 - val_auc: 0.9987\n",
      "Epoch 22/200\n",
      "1052/1052 [==============================] - 2582s 2s/step - loss: 0.1990 - tp: 62823.0000 - fp: 2810.0000 - tn: 871817.0000 - fn: 4456.0000 - accuracy: 0.9923 - precision: 0.9572 - recall: 0.9338 - auc: 0.9959 - val_loss: 0.0711 - val_tp: 3461.0000 - val_fp: 61.0000 - val_tn: 46115.0000 - val_fn: 91.0000 - val_accuracy: 0.9969 - val_precision: 0.9827 - val_recall: 0.9744 - val_auc: 0.9994\n",
      "Epoch 23/200\n",
      "1052/1052 [==============================] - 2325s 2s/step - loss: 0.1997 - tp: 62859.0000 - fp: 2801.0000 - tn: 871826.0000 - fn: 4420.0000 - accuracy: 0.9923 - precision: 0.9573 - recall: 0.9343 - auc: 0.9958 - val_loss: 0.0899 - val_tp: 3439.0000 - val_fp: 69.0000 - val_tn: 46107.0000 - val_fn: 113.0000 - val_accuracy: 0.9963 - val_precision: 0.9803 - val_recall: 0.9682 - val_auc: 0.9994\n",
      "Epoch 24/200\n",
      "1052/1052 [==============================] - 2328s 2s/step - loss: 0.1964 - tp: 62862.0000 - fp: 2774.0000 - tn: 871853.0000 - fn: 4417.0000 - accuracy: 0.9924 - precision: 0.9577 - recall: 0.9343 - auc: 0.9958 - val_loss: 0.1007 - val_tp: 3430.0000 - val_fp: 72.0000 - val_tn: 46104.0000 - val_fn: 122.0000 - val_accuracy: 0.9961 - val_precision: 0.9794 - val_recall: 0.9657 - val_auc: 0.9990\n",
      "Epoch 25/200\n",
      "1052/1052 [==============================] - 2306s 2s/step - loss: 0.2021 - tp: 62794.0000 - fp: 2766.0000 - tn: 871861.0000 - fn: 4485.0000 - accuracy: 0.9923 - precision: 0.9578 - recall: 0.9333 - auc: 0.9956 - val_loss: 0.0705 - val_tp: 3471.0000 - val_fp: 52.0000 - val_tn: 46124.0000 - val_fn: 81.0000 - val_accuracy: 0.9973 - val_precision: 0.9852 - val_recall: 0.9772 - val_auc: 0.9995\n",
      "Epoch 26/200\n",
      "1052/1052 [==============================] - 2312s 2s/step - loss: 0.1957 - tp: 62960.0000 - fp: 2748.0000 - tn: 871879.0000 - fn: 4319.0000 - accuracy: 0.9925 - precision: 0.9582 - recall: 0.9358 - auc: 0.9959 - val_loss: 0.0758 - val_tp: 3458.0000 - val_fp: 57.0000 - val_tn: 46119.0000 - val_fn: 94.0000 - val_accuracy: 0.9970 - val_precision: 0.9838 - val_recall: 0.9735 - val_auc: 0.9996\n",
      "Epoch 27/200\n",
      "1052/1052 [==============================] - 2297s 2s/step - loss: 0.1968 - tp: 62895.0000 - fp: 2777.0000 - tn: 871850.0000 - fn: 4384.0000 - accuracy: 0.9924 - precision: 0.9577 - recall: 0.9348 - auc: 0.9957 - val_loss: 0.0765 - val_tp: 3457.0000 - val_fp: 49.0000 - val_tn: 46127.0000 - val_fn: 95.0000 - val_accuracy: 0.9971 - val_precision: 0.9860 - val_recall: 0.9733 - val_auc: 0.9995\n",
      "Epoch 28/200\n",
      "1052/1052 [==============================] - 2278s 2s/step - loss: 0.1926 - tp: 62915.0000 - fp: 2746.0000 - tn: 871881.0000 - fn: 4364.0000 - accuracy: 0.9925 - precision: 0.9582 - recall: 0.9351 - auc: 0.9962 - val_loss: 0.1105 - val_tp: 3418.0000 - val_fp: 98.0000 - val_tn: 46078.0000 - val_fn: 134.0000 - val_accuracy: 0.9953 - val_precision: 0.9721 - val_recall: 0.9623 - val_auc: 0.9988\n",
      "Epoch 29/200\n",
      "1052/1052 [==============================] - 2309s 2s/step - loss: 0.1970 - tp: 62917.0000 - fp: 2638.0000 - tn: 871989.0000 - fn: 4362.0000 - accuracy: 0.9926 - precision: 0.9598 - recall: 0.9352 - auc: 0.9958 - val_loss: 0.0787 - val_tp: 3454.0000 - val_fp: 64.0000 - val_tn: 46112.0000 - val_fn: 98.0000 - val_accuracy: 0.9967 - val_precision: 0.9818 - val_recall: 0.9724 - val_auc: 0.9996\n",
      "Epoch 30/200\n",
      "1052/1052 [==============================] - 2309s 2s/step - loss: 0.1950 - tp: 62909.0000 - fp: 2735.0000 - tn: 871892.0000 - fn: 4370.0000 - accuracy: 0.9925 - precision: 0.9583 - recall: 0.9350 - auc: 0.9959 - val_loss: 0.1361 - val_tp: 3377.0000 - val_fp: 112.0000 - val_tn: 46064.0000 - val_fn: 175.0000 - val_accuracy: 0.9942 - val_precision: 0.9679 - val_recall: 0.9507 - val_auc: 0.9986\n",
      "Epoch 31/200\n",
      "1052/1052 [==============================] - 2471s 2s/step - loss: 0.1872 - tp: 63079.0000 - fp: 2669.0000 - tn: 871958.0000 - fn: 4200.0000 - accuracy: 0.9927 - precision: 0.9594 - recall: 0.9376 - auc: 0.9961 - val_loss: 0.0653 - val_tp: 3483.0000 - val_fp: 41.0000 - val_tn: 46135.0000 - val_fn: 69.0000 - val_accuracy: 0.9978 - val_precision: 0.9884 - val_recall: 0.9806 - val_auc: 0.9993\n"
     ]
    }
   ],
   "source": [
    "tf.get_logger().setLevel('WARNING') #\n",
    "tf.get_logger().setLevel('ERROR') # \n",
    "\n",
    "# Create folders and callbacks and fit\n",
    "train_callbacks = create_folders_and_callbacks(model_name='incresnet')\n",
    "\n",
    "# Train the model\n",
    "tl_history = tl_model.fit(\n",
    "    x = train_gen,\n",
    "    epochs = 200,\n",
    "    validation_data = valid_gen,\n",
    "    callbacks = train_callbacks\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2cbe1232-00a6-4947-8bd7-2d09869d2e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best epoch model\n",
    "tl_model.save(\"best_model/incresnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c33356-ffe0-4b3a-bf9a-1cde01e3d3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
